{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0dvXm9Z2/QVzqQEAYvtlS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasEPrz/APRENDIZAJE-POR-REFUERZO/blob/main/Lab2/Lab2_Perez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actividad 1**\n",
        "\n",
        "Crear tu propio entorno y entrenar agentes RL en el mismo. Analizar la convergencia con distintos algoritmos* (ej: PPO, DQN), resultados con distintas funciones de recompensa e híper-parámetros.\n",
        "\n",
        "Algunas ideas:\n",
        "\n",
        "Transformar GoLeftEnv en una grilla 2D, añadir paredes / trampas / agua.\n",
        "Crear un entorno que juegue a algún juego como el ta-te-ti.\n",
        "Crea un entorno totalmente nuevo que sea de tu interés!"
      ],
      "metadata": {
        "id": "Lx7G4_oiKvrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creación del entorno**"
      ],
      "metadata": {
        "id": "AY9bAaTyLBkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir la estructura del entorno"
      ],
      "metadata": {
        "id": "16Fu2zDOLUX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "class CustomGridEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(CustomGridEnv, self).__init__()\n",
        "\n",
        "        self.grid_size = 5  # Tamaño de la grilla (5x5)\n",
        "        self.agent_pos = [0, 0]  # Posición inicial del agente (en la esquina superior izquierda)\n",
        "        self.goal_pos = [4, 4]  # Posición del objetivo (en la esquina inferior derecha)\n",
        "\n",
        "        # Definir la acción: [arriba, abajo, izquierda, derecha]\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        # Definir el espacio de observación: matriz 5x5, donde 0 = vacío, 1 = pared, 2 = trampa, 3 = objetivo\n",
        "        self.observation_space = spaces.Box(low=0, high=3, shape=(self.grid_size, self.grid_size), dtype=int)\n",
        "\n",
        "        # Mapa con paredes y trampas\n",
        "        self.grid = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.grid[1, 1] = 1  # Pared en (1,1)\n",
        "        self.grid[2, 2] = 2  # Trampa en (2,2)\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_pos = [0, 0]  # Reiniciar la posición del agente\n",
        "        return self.grid  # Devuelve el estado inicial de la grilla\n",
        "\n",
        "    def step(self, action):\n",
        "        # Mover al agente en función de la acción\n",
        "        if action == 0:  # Arriba\n",
        "            self.agent_pos[0] = max(0, self.agent_pos[0] - 1)\n",
        "        elif action == 1:  # Abajo\n",
        "            self.agent_pos[0] = min(self.grid_size - 1, self.agent_pos[0] + 1)\n",
        "        elif action == 2:  # Izquierda\n",
        "            self.agent_pos[1] = max(0, self.agent_pos[1] - 1)\n",
        "        elif action == 3:  # Derecha\n",
        "            self.agent_pos[1] = min(self.grid_size - 1, self.agent_pos[1] + 1)\n",
        "\n",
        "        # Verificar si el agente ha llegado al objetivo o ha caído en una trampa\n",
        "        done = False\n",
        "        reward = -1  # Penalización por cada paso\n",
        "        if self.agent_pos == self.goal_pos:\n",
        "            reward = 10  # Recompensa por llegar al objetivo\n",
        "            done = True\n",
        "        elif self.grid[self.agent_pos[0], self.agent_pos[1]] == 2:  # Si cae en una trampa\n",
        "            reward = -10  # Recompensa negativa por caer en una trampa\n",
        "            done = True\n",
        "\n",
        "        return self.grid, reward, done, {}\n",
        "\n",
        "    def render(self):\n",
        "        # Imprimir la grilla para visualizar el entorno\n",
        "        grid_copy = self.grid.copy()\n",
        "        grid_copy[self.agent_pos[0], self.agent_pos[1]] = 5  # Representar al agente con un 5\n",
        "        print(grid_copy)\n"
      ],
      "metadata": {
        "id": "-SKiN6x2LNWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenar el agente con un algoritmo de RL**"
      ],
      "metadata": {
        "id": "lPj7TA52LcLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'shimmy>=2.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg6fS_4eNh2s",
        "outputId": "08871979-1354-4efe-f8df-4ea3621bcc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy>=2.0\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy>=2.0) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.10/dist-packages (from shimmy>=2.0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8s9gs5CLhrW",
        "outputId": "57bc7d92-c927-4b9b-9aae-f63309325386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.17.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.10.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (11.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar el agente con PPO"
      ],
      "metadata": {
        "id": "7WFsn2Y1N7h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# Crear el entorno\n",
        "env = CustomGridEnv()\n",
        "\n",
        "# Vectorizar el entorno\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "# Crear y entrenar el agente PPO\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMlKIdj7Lo5z",
        "outputId": "c090b2a0-883c-4c6e-ae14-457737e15a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1026 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 1    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 668        |\n",
            "|    iterations           | 2          |\n",
            "|    time_elapsed         | 6          |\n",
            "|    total_timesteps      | 4096       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01902721 |\n",
            "|    clip_fraction        | 0.31       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.37      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 13         |\n",
            "|    n_updates            | 10         |\n",
            "|    policy_gradient_loss | -0.0263    |\n",
            "|    value_loss           | 75.7       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 664         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018353956 |\n",
            "|    clip_fraction        | 0.334       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.32       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 38.8        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0254     |\n",
            "|    value_loss           | 76.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 662         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015977047 |\n",
            "|    clip_fraction        | 0.256       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.25       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 43.3        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0203     |\n",
            "|    value_loss           | 84.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 654         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014817617 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 31.6        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0193     |\n",
            "|    value_loss           | 76.9        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7c30e8c66e00>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analizar la convergencia"
      ],
      "metadata": {
        "id": "Bk_0f4syONOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=0.001, n_steps=256, gamma=0.99, ent_coef=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnIi6s2VOL8O",
        "outputId": "ee608a10-6cbb-418f-a769-9fc5d7ab9ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluación del agente"
      ],
      "metadata": {
        "id": "RLusZMp1OmXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.reset()\n",
        "for _ in range(1000):\n",
        "    action, _states = model.predict(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "    if done:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKm0E8ytOpIU",
        "outputId": "5339a400-193e-4019-bcdd-3732d329b402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
            "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probar con otros algoritmos (DQN)"
      ],
      "metadata": {
        "id": "i5zkIkZ3OvbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "# Entrenar con DQN\n",
        "model_dqn = DQN(\"MlpPolicy\", env, verbose=1)\n",
        "model_dqn.learn(total_timesteps=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6crt3Bh8O0Cx",
        "outputId": "c6a5ca3e-999c-4d32-e097-62bedd23e969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.578    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 1391     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 444      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.687    |\n",
            "|    n_updates        | 85       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 985      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2528     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000332 |\n",
            "|    n_updates        | 606      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 917      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 4542     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.56e-07 |\n",
            "|    n_updates        | 1110     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 820      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6490     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.59e-06 |\n",
            "|    n_updates        | 1597     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 828      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7123     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.28e-07 |\n",
            "|    n_updates        | 1755     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 839      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7995     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.76e-06 |\n",
            "|    n_updates        | 1973     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 846      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8734     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.85e-07 |\n",
            "|    n_updates        | 2158     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 849      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9411     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.52e-06 |\n",
            "|    n_updates        | 2327     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 853      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9972     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.89e-07 |\n",
            "|    n_updates        | 2467     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7c2fbd750b80>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficar la convergencia"
      ],
      "metadata": {
        "id": "GgjXNXjQO6k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.vec_env import VecNormalize\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "eval_callback = EvalCallback(env, best_model_save_path='./logs/', log_path='./logs/', eval_freq=5000, deterministic=True, render=False)\n",
        "\n",
        "# Entrenar el modelo con el callback\n",
        "model.learn(total_timesteps=10000, callback=eval_callback)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzs0RyFVO8wc",
        "outputId": "6a0a44cb-cf75-4ddd-fb88-c5beb7400cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1187 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 0    |\n",
            "|    total_timesteps | 256  |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 846         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 0           |\n",
            "|    total_timesteps      | 512         |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015029857 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.02       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 28.4        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0203     |\n",
            "|    value_loss           | 57.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 766         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 768         |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016991742 |\n",
            "|    clip_fraction        | 0.0816      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.955      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 21.9        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00212    |\n",
            "|    value_loss           | 42.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 729         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 1024        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010240927 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.963      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 19.5        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0098     |\n",
            "|    value_loss           | 43.5        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 692           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 1             |\n",
            "|    total_timesteps      | 1280          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00089663104 |\n",
            "|    clip_fraction        | 0.0297        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.964        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 24            |\n",
            "|    n_updates            | 100           |\n",
            "|    policy_gradient_loss | -0.00438      |\n",
            "|    value_loss           | 44.7          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 644          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 1536         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029059965 |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.898       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 17           |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.0129      |\n",
            "|    value_loss           | 34.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 620          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 1792         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066154283 |\n",
            "|    clip_fraction        | 0.0824       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.863       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 22.9         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00718     |\n",
            "|    value_loss           | 42.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 603          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 3            |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017329413 |\n",
            "|    clip_fraction        | 0.00469      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.866       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 15.8         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | 7.84e-05     |\n",
            "|    value_loss           | 36.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 583         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 2304        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010308495 |\n",
            "|    clip_fraction        | 0.0484      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.853      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 19.9        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00545    |\n",
            "|    value_loss           | 41.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 568         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 2560        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009346618 |\n",
            "|    clip_fraction        | 0.0484      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.849      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 33.4        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00134    |\n",
            "|    value_loss           | 51.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 558        |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 5          |\n",
            "|    total_timesteps      | 2816       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01387301 |\n",
            "|    clip_fraction        | 0.131      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.846     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.001      |\n",
            "|    loss                 | 22.8       |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | -0.013     |\n",
            "|    value_loss           | 43.3       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 562         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 3072        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024869544 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.794      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 22.6        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00505    |\n",
            "|    value_loss           | 41.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 567         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 3328        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006484837 |\n",
            "|    clip_fraction        | 0.0676      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.792      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 22.3        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00405    |\n",
            "|    value_loss           | 41.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 572         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 3584        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017563844 |\n",
            "|    clip_fraction        | 0.052       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.8        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 23.6        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00125    |\n",
            "|    value_loss           | 37.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 576         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 3840        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004906596 |\n",
            "|    clip_fraction        | 0.0145      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.773      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 21          |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.000811   |\n",
            "|    value_loss           | 41.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 581          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040554805 |\n",
            "|    clip_fraction        | 0.0637       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.78        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 19.8         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    value_loss           | 37.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 585         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 4352        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021610634 |\n",
            "|    clip_fraction        | 0.191       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.743      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 20.5        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    value_loss           | 39          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 588         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 4608        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023507591 |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.766      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 16.4        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0216     |\n",
            "|    value_loss           | 34          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 4864        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021189421 |\n",
            "|    clip_fraction        | 0.173       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.778      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 12.8        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00608    |\n",
            "|    value_loss           | 40          |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ti3ruqv6ss14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}